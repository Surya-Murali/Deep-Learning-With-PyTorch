{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install --proxy http://one.proxy.att.com:8080 torch\n",
    "#!pip install --proxy http://one.proxy.att.com:8080 torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "import time\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/Users/sm912r/PycharmProjects/CV/pinnacle_buried_wire_usecase_train_test'\n",
    "train_dir = data_dir + '/train'\n",
    "valid_dir = data_dir + '/valid'\n",
    "test_dir = data_dir + '/test'\n",
    "\n",
    "\n",
    "train_transforms = transforms.Compose([transforms.RandomRotation(30),\n",
    "                                         transforms.RandomResizedCrop(224),\n",
    "                                         transforms.RandomHorizontalFlip(p = 0.6),\n",
    "                                         transforms.RandomVerticalFlip(p = 0.4),\n",
    "                                         transforms.ToTensor(),\n",
    "                                         transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                              [0.229, 0.224, 0.225])])\n",
    "test_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "valid_transforms = transforms.Compose([transforms.Resize(255),\n",
    "                                      transforms.CenterCrop(224),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                                                           [0.229, 0.224, 0.225])])\n",
    "\n",
    "# TODO: Load the datasets with ImageFolder\n",
    "train_data = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "valid_data = datasets.ImageFolder(valid_dir, transform=valid_transforms)\n",
    "\n",
    "# TODO: Using the image datasets and the trainforms, define the dataloaders\n",
    "trainloader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(test_data, batch_size=64)\n",
    "validloader = torch.utils.data.DataLoader(valid_data, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'0-0-0-1': 0, '0-0-1-0': 1, '0-1-0-0': 2, '1-0-0-0': 3}\n",
      "{'0-0-0-1': 0, '0-0-1-0': 1, '0-1-0-0': 2, '1-0-0-0': 3}\n",
      "{'test_data': 0}\n"
     ]
    }
   ],
   "source": [
    "print(train_data.class_to_idx)\n",
    "print(train_data.class_to_idx)\n",
    "print(test_data.class_to_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675\n",
      "79\n",
      "255\n"
     ]
    }
   ],
   "source": [
    "print(len(trainloader.dataset))\n",
    "print(len(validloader.dataset))\n",
    "print(len(testloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0-0-0-1', '0-0-1-0', '0-1-0-0', '1-0-0-0']\n",
      "['0-0-0-1', '0-0-1-0', '0-1-0-0', '1-0-0-0']\n"
     ]
    }
   ],
   "source": [
    "print(trainloader.dataset.classes)\n",
    "print(validloader.dataset.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "675\n",
      "79\n"
     ]
    }
   ],
   "source": [
    "print(len(trainloader.dataset))\n",
    "print(len(validloader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEEP LEARNING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "print(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([-9.0540e-03, -4.1489e-03, -2.0516e-02, -1.7642e-02,  9.6078e-03,\n",
       "         5.8760e-03, -1.4448e-02,  7.1637e-04,  1.4057e-03, -1.6386e-03,\n",
       "        -1.2073e-02, -9.3700e-03, -1.9250e-02, -1.7166e-02, -1.1226e-02,\n",
       "        -1.6972e-02, -8.1289e-03, -1.3626e-02,  8.5068e-03, -1.7855e-02,\n",
       "         6.9540e-03,  1.8412e-02, -2.4812e-03,  2.4328e-03, -1.3534e-03,\n",
       "         4.8874e-03,  1.0521e-02, -8.0455e-04, -6.4342e-03, -1.1446e-02,\n",
       "        -1.3326e-02, -9.2675e-03, -2.5020e-03, -4.5003e-03,  3.7125e-03,\n",
       "        -2.4581e-02,  4.4222e-03, -8.4804e-03, -8.9190e-06, -1.7266e-03,\n",
       "        -4.1818e-03,  2.4226e-03,  9.5379e-03, -6.6336e-03,  2.2586e-03,\n",
       "         3.6322e-04,  2.7801e-02, -1.1270e-02, -1.5046e-02, -8.3841e-03,\n",
       "         5.7193e-03, -1.5327e-02,  8.8598e-04,  2.3715e-02,  1.3557e-02,\n",
       "         6.5433e-03,  1.3621e-02, -9.8292e-03,  7.2298e-03,  1.7554e-02,\n",
       "         2.0959e-04,  4.3992e-03, -8.7419e-03,  9.7137e-03,  1.1456e-02,\n",
       "         1.5336e-02, -6.9862e-03, -1.3379e-03,  5.0565e-03, -1.4394e-03,\n",
       "        -2.0059e-02,  6.6472e-03,  7.4694e-04, -7.4046e-04,  3.9481e-03,\n",
       "         1.8126e-03,  2.2948e-03,  5.0710e-03,  4.2257e-03,  6.9578e-03,\n",
       "        -1.4057e-02,  1.2723e-02,  5.3173e-03, -3.3818e-02, -1.4235e-02,\n",
       "        -3.0357e-03, -1.1859e-02,  1.1082e-03, -5.6086e-04,  8.8305e-03,\n",
       "        -6.6599e-03, -1.0402e-02,  8.7649e-03, -3.4985e-03, -1.0276e-02,\n",
       "        -1.9184e-02, -1.6150e-03, -1.0940e-02, -1.7612e-02, -5.9452e-05,\n",
       "        -6.8167e-03, -1.5879e-02, -2.0135e-03,  7.3849e-03,  4.6699e-03,\n",
       "        -1.1819e-02, -2.2258e-03, -1.0042e-02, -1.4626e-02, -2.9059e-02,\n",
       "        -1.9744e-02,  2.1017e-02, -4.9493e-03, -1.4729e-02, -5.7178e-03,\n",
       "        -2.7879e-02, -1.1342e-02, -1.1067e-02,  3.6126e-03, -1.6722e-03,\n",
       "        -5.8225e-03, -1.1147e-02, -5.8773e-03, -1.3853e-02,  7.6938e-03,\n",
       "        -3.1506e-04, -1.1560e-02,  1.6636e-03, -8.3648e-03, -1.7294e-03,\n",
       "        -1.3527e-02,  1.2758e-03,  3.0125e-03,  2.0911e-03, -1.6461e-03,\n",
       "        -1.9466e-02, -8.0977e-03, -1.3765e-02,  4.7957e-03, -1.8019e-02,\n",
       "        -1.7326e-02, -3.8022e-03, -2.5910e-02, -4.7377e-03, -1.1454e-02,\n",
       "         1.9997e-03,  1.3955e-03, -2.2347e-02, -9.7723e-03, -1.5300e-02,\n",
       "        -1.3231e-03,  8.4604e-03, -1.9220e-02,  1.1905e-02, -4.7311e-04,\n",
       "        -3.2012e-03, -2.0542e-03, -1.1135e-02, -6.5770e-03, -3.0687e-03,\n",
       "        -7.1176e-04,  9.2847e-04,  3.3504e-02,  1.1147e-02, -2.3674e-03,\n",
       "        -6.1488e-03, -2.9458e-03, -1.9080e-02,  7.8941e-04, -7.8993e-03,\n",
       "         9.5198e-03,  1.6350e-02,  8.9761e-03,  8.0201e-03,  9.6033e-03,\n",
       "        -1.1656e-02,  6.9022e-03, -7.3137e-03,  1.3641e-02,  5.3347e-03,\n",
       "         3.9581e-03, -6.1368e-03,  7.6379e-03, -1.1373e-02,  7.7446e-03,\n",
       "         9.7012e-03, -2.3150e-03,  9.7793e-03,  3.0096e-03,  4.5153e-03,\n",
       "        -7.5008e-03,  9.4292e-03,  2.2289e-02, -1.6589e-02, -6.2875e-03,\n",
       "         2.1770e-02,  1.1185e-02,  7.9690e-03, -2.3495e-02,  6.2308e-03,\n",
       "        -1.7196e-02,  8.5162e-03,  1.8709e-02,  1.8687e-02,  1.4016e-02,\n",
       "        -3.9788e-04, -2.1075e-02,  3.5216e-03, -4.6406e-03,  1.9511e-02,\n",
       "        -1.0128e-02,  8.2909e-03, -1.3885e-03, -1.0802e-02,  2.1202e-03,\n",
       "        -3.6062e-04, -7.9470e-03,  2.5781e-02,  3.0053e-03,  3.5437e-03,\n",
       "         2.1905e-03, -1.2686e-02, -1.7843e-03,  2.8698e-02, -1.6651e-02,\n",
       "         1.9534e-02, -1.8055e-03,  6.1631e-03, -8.6250e-03,  4.9767e-03,\n",
       "         5.5962e-04, -4.8662e-03,  1.8979e-02,  4.0372e-04,  7.4906e-03,\n",
       "        -3.6779e-03,  2.4809e-02,  6.1266e-03,  7.1814e-03,  2.3046e-02,\n",
       "        -5.0567e-03, -2.6188e-03,  3.8702e-03, -4.8383e-03,  2.9464e-03,\n",
       "         1.6378e-02,  2.4133e-03,  6.3303e-03,  1.1527e-03, -6.9009e-03,\n",
       "         8.5641e-03,  1.1656e-02, -3.9624e-04, -1.5257e-02,  1.2500e-02,\n",
       "        -3.1723e-03,  9.7659e-03,  2.0472e-03,  1.3458e-02,  3.1983e-03,\n",
       "         6.1478e-03, -5.5542e-03,  4.5304e-03,  9.5399e-03, -8.0610e-04,\n",
       "        -2.6285e-03,  9.3042e-03, -2.6574e-03, -1.7429e-02,  4.1200e-03,\n",
       "         2.1546e-02, -6.7119e-03,  3.5949e-03,  1.0285e-02, -8.3183e-03,\n",
       "        -1.3146e-02,  5.1571e-03, -4.9292e-03, -5.1749e-03,  3.9995e-03,\n",
       "        -1.1157e-02,  2.3007e-02, -1.3237e-02, -1.3539e-02,  1.6401e-02,\n",
       "         1.8551e-02, -6.2334e-03, -4.0546e-03, -5.4428e-03, -8.5930e-03,\n",
       "        -9.7738e-03, -1.7880e-02, -4.2471e-03, -8.9907e-03, -4.4864e-03,\n",
       "        -3.3912e-03, -9.0068e-03, -7.6528e-03,  1.4259e-04,  1.2927e-02,\n",
       "        -1.0614e-02, -3.2305e-03, -7.8824e-03, -3.4433e-03, -7.5388e-03,\n",
       "         1.0577e-02,  1.6554e-02, -8.3268e-04, -1.3322e-02, -5.6734e-03,\n",
       "         4.8978e-03,  3.2308e-03,  4.4596e-03,  2.1594e-02,  2.2659e-02,\n",
       "         6.1472e-03,  5.5816e-03, -3.1229e-03,  9.6828e-03, -3.1044e-03,\n",
       "        -2.2434e-02, -1.8109e-02, -2.5078e-02, -1.4465e-02, -2.1683e-02,\n",
       "        -2.1719e-02, -2.2218e-02, -4.0805e-03, -6.8154e-03, -4.6295e-04,\n",
       "         2.1050e-03, -1.9103e-03, -2.2263e-04,  3.1099e-03, -3.9733e-03,\n",
       "        -1.5902e-02,  1.4425e-02, -1.6939e-02, -8.6551e-03, -9.6204e-03,\n",
       "        -8.7589e-03, -1.0852e-02,  8.5307e-04, -1.8470e-03, -7.0786e-03,\n",
       "         6.6244e-04,  6.5149e-03, -9.2485e-03,  1.3138e-02, -9.2627e-03,\n",
       "         1.2277e-02, -6.7726e-03, -4.5025e-03, -2.4775e-03, -3.2238e-03,\n",
       "        -6.2376e-03, -3.1175e-05, -8.4149e-03,  1.1946e-02,  1.2635e-02,\n",
       "         9.7893e-03,  1.1308e-02, -5.7688e-04, -2.0763e-03, -4.9488e-03,\n",
       "         8.9936e-04, -1.4518e-02,  9.4824e-03, -8.2777e-03,  7.6667e-03,\n",
       "        -7.6525e-03, -5.0149e-03, -2.0475e-03,  3.6663e-03, -4.1791e-03,\n",
       "        -7.1726e-03, -7.5156e-04, -1.2771e-02,  1.0262e-02,  9.8359e-03,\n",
       "        -1.6181e-02,  2.4103e-03,  2.2923e-03,  4.0631e-03, -2.1448e-02,\n",
       "        -7.8552e-03,  2.7749e-03, -7.1327e-03, -1.8056e-02, -4.4744e-03,\n",
       "        -9.6018e-03,  1.4480e-02, -1.8536e-02, -2.3572e-02, -9.6817e-03,\n",
       "        -9.1566e-03, -2.3145e-02, -1.1013e-02, -1.0774e-02,  4.0369e-03,\n",
       "        -1.5529e-02,  1.1558e-02,  2.9494e-03,  4.5030e-03, -2.6361e-02,\n",
       "         1.6857e-02, -6.7117e-04, -8.6142e-03, -1.5695e-02,  2.5245e-04,\n",
       "        -1.0122e-03, -6.8395e-03,  4.6690e-03,  1.8952e-02,  1.5193e-02,\n",
       "        -2.3246e-03,  3.8103e-03, -9.5545e-03,  6.1614e-03,  7.6473e-03,\n",
       "        -2.8300e-03,  4.8893e-04,  8.8167e-03,  1.7012e-02,  1.5419e-02,\n",
       "        -8.8604e-05, -2.6620e-02, -1.1690e-02,  1.1404e-02,  4.8491e-03,\n",
       "        -6.3126e-03,  7.5267e-03, -5.7180e-03,  1.3621e-02,  6.8829e-03,\n",
       "        -4.1245e-03, -8.8954e-04,  3.1794e-03,  3.3397e-03, -9.8891e-03,\n",
       "         9.5482e-03,  1.3731e-03,  3.3720e-03, -3.5529e-03,  1.0321e-02,\n",
       "         1.9340e-02,  1.2044e-02, -2.5388e-03,  2.2359e-02,  5.6450e-03,\n",
       "         4.2535e-03, -4.7033e-03, -4.3303e-03, -4.9201e-03,  4.0193e-03,\n",
       "         7.9716e-04,  1.4354e-02,  1.0510e-02, -1.6068e-02,  1.0776e-02,\n",
       "         2.4135e-03, -3.1489e-03,  4.0862e-03,  1.5338e-02,  2.7293e-02,\n",
       "        -6.6519e-03, -8.8138e-03,  2.0641e-03,  1.0558e-02, -1.1751e-03,\n",
       "         2.6450e-02, -4.5885e-03, -2.5581e-03,  2.2879e-03, -1.6937e-02,\n",
       "        -1.6884e-02, -2.2681e-02,  5.2053e-04, -1.3454e-02,  1.3260e-03,\n",
       "         8.3329e-03, -3.0078e-03,  1.6696e-03, -4.7768e-03,  1.3149e-03,\n",
       "        -3.2169e-03,  2.9908e-03,  2.5137e-02,  6.4319e-03,  2.6557e-03,\n",
       "        -2.0985e-02,  5.1428e-03,  3.7225e-03, -1.8776e-03,  9.8686e-04,\n",
       "        -7.6931e-03, -4.7424e-03, -1.0604e-02, -4.8097e-03, -3.3184e-03,\n",
       "        -1.8420e-02, -1.3153e-02,  7.3985e-03, -2.7261e-04, -1.7159e-03,\n",
       "        -1.3054e-03,  7.0221e-03,  2.1518e-04,  7.5642e-03, -1.6226e-02,\n",
       "        -1.0975e-02,  7.3913e-03,  1.3499e-03,  3.4619e-03, -1.0177e-02,\n",
       "         2.1055e-02, -5.6968e-03, -5.8522e-03, -2.8396e-03,  1.5228e-03,\n",
       "        -1.6070e-02, -4.4185e-03,  1.0954e-02,  1.5877e-02, -1.0259e-02,\n",
       "        -2.3040e-02,  1.4476e-02,  1.3044e-02, -3.5107e-03,  1.4101e-02,\n",
       "         1.4979e-02, -4.6421e-03,  1.1947e-02,  1.9238e-03,  8.4225e-03,\n",
       "         6.4436e-03,  1.7598e-03,  1.1681e-02,  9.4544e-03,  1.9474e-02,\n",
       "        -2.6913e-02,  4.3572e-03,  6.4584e-03, -1.1189e-03,  7.1997e-03,\n",
       "         2.5116e-03, -2.7444e-04, -1.2989e-02, -9.0542e-03, -5.0313e-03,\n",
       "         3.0390e-03,  2.0017e-03,  4.2103e-05,  1.5548e-03, -7.3574e-03,\n",
       "        -1.8541e-03, -1.9903e-02,  2.1203e-02,  8.1240e-03,  9.4240e-03,\n",
       "        -6.1419e-03, -3.2745e-03, -6.8238e-03,  1.2302e-02, -1.2866e-02,\n",
       "        -4.0878e-03, -9.0624e-03,  2.0396e-02, -7.1515e-03, -5.0075e-03,\n",
       "        -1.8688e-03,  5.4391e-03,  7.7934e-03, -6.8209e-03,  1.8686e-03,\n",
       "         2.0032e-03,  4.4714e-04,  2.9370e-03, -5.6603e-04,  9.7942e-03,\n",
       "        -2.4189e-03, -2.7806e-03,  1.6427e-02,  1.3859e-02,  1.6110e-02,\n",
       "        -6.9551e-04, -2.0631e-02,  1.3816e-02,  7.7730e-04, -5.9685e-04,\n",
       "        -6.0041e-03, -2.6906e-03, -6.7904e-03,  1.8637e-02, -3.1624e-03,\n",
       "        -6.1068e-03, -5.3474e-03,  1.0279e-02, -8.5100e-03, -3.9488e-03,\n",
       "         1.1338e-02,  1.3868e-02,  3.8278e-03, -4.0237e-03, -1.0225e-02,\n",
       "         4.0387e-03,  2.6453e-03,  2.6120e-03,  8.6405e-03, -1.1117e-02,\n",
       "         1.4388e-02, -1.4128e-02, -1.2018e-02, -1.0592e-02, -6.6603e-03,\n",
       "         7.9171e-03,  4.0072e-03, -7.6342e-03,  1.6426e-02, -1.0826e-02,\n",
       "         1.0751e-02,  8.9987e-03,  1.3392e-02,  3.4955e-02,  1.2790e-02,\n",
       "         6.5807e-03,  1.7475e-02,  9.3045e-03, -4.9896e-03,  1.4937e-02,\n",
       "         1.5019e-04, -1.1449e-02,  1.7550e-02, -6.4155e-03, -7.5740e-03,\n",
       "        -7.9086e-03,  7.7305e-03, -4.9878e-03,  4.6029e-03, -1.3565e-02,\n",
       "        -1.9914e-02,  1.3758e-02,  5.6335e-03,  2.4345e-03,  2.7075e-02,\n",
       "        -8.6951e-03,  2.6696e-02, -1.8396e-02,  6.7324e-03,  8.8317e-03,\n",
       "         3.7132e-02,  1.7988e-03,  5.6044e-03,  5.8572e-03,  1.1837e-02,\n",
       "         2.2514e-02,  1.2283e-03,  2.3551e-03, -8.6822e-03,  1.1198e-02,\n",
       "         6.2164e-04, -7.5180e-03,  4.8814e-03,  1.9022e-03,  8.9163e-03,\n",
       "         1.7953e-02,  7.1988e-03,  3.7652e-03, -2.0105e-02, -1.9763e-02,\n",
       "         3.2020e-03,  1.8837e-02,  1.2321e-02,  1.3820e-02,  4.1368e-03,\n",
       "        -1.6280e-02, -2.9063e-03,  2.7845e-02,  6.1211e-03,  5.3014e-03,\n",
       "         7.0098e-03,  2.2649e-02,  1.1360e-03,  2.9727e-02,  1.3664e-02,\n",
       "        -6.8027e-03,  1.4364e-02, -5.5152e-03, -1.4049e-02, -1.0417e-02,\n",
       "        -2.3374e-02, -4.5921e-03,  2.1876e-02, -9.0628e-03, -6.1995e-03,\n",
       "         1.2690e-02,  8.1973e-03, -1.0950e-02, -5.6462e-03, -4.7800e-04,\n",
       "         2.3818e-02,  9.5816e-04, -4.7822e-03,  8.7511e-03,  1.4342e-02,\n",
       "        -1.6386e-02, -9.0176e-04,  4.6307e-04, -2.2330e-03, -1.1017e-02,\n",
       "        -7.3926e-03,  8.6733e-03, -9.6236e-03,  5.8556e-03,  6.5153e-03,\n",
       "        -7.7699e-03,  2.1073e-02, -9.3213e-03,  1.3332e-02,  1.6535e-02,\n",
       "         5.1240e-03, -3.4339e-03,  2.4813e-02, -6.0891e-03, -8.6840e-03,\n",
       "         2.1645e-03, -3.5292e-03, -1.2985e-02, -9.5567e-03, -3.7438e-03,\n",
       "         3.2002e-03,  1.5815e-02,  8.0564e-03,  7.5541e-03, -1.0808e-02,\n",
       "        -6.4124e-04, -1.4614e-03,  3.7593e-03, -3.1028e-03,  1.0774e-02,\n",
       "        -4.6029e-03, -9.1495e-03,  8.3655e-04,  9.2427e-03,  1.3866e-02,\n",
       "         5.6882e-03, -3.3533e-03,  2.7270e-04, -4.6015e-03,  1.9522e-02,\n",
       "         4.0074e-03, -6.9705e-03,  1.3168e-02,  2.0821e-03,  9.5050e-03,\n",
       "        -2.3545e-03,  6.2672e-03, -1.2549e-02,  8.4020e-03,  7.7575e-03,\n",
       "         2.6701e-03,  9.9543e-03, -1.1701e-02,  1.6242e-03,  8.8834e-03,\n",
       "         4.9853e-03, -1.3091e-02, -6.0042e-03,  4.7919e-03,  8.4710e-03,\n",
       "        -3.4157e-03, -1.1133e-02,  1.2986e-02,  5.0915e-03,  2.0220e-02,\n",
       "        -1.7791e-03,  9.3522e-03,  1.9787e-02, -2.5497e-03, -1.0211e-02,\n",
       "        -1.3922e-02, -4.6255e-03,  3.8947e-03,  1.3278e-03,  6.0785e-03,\n",
       "         6.1298e-03, -2.9151e-03, -6.8150e-03,  5.6859e-03,  1.0645e-02,\n",
       "        -1.6793e-02,  1.6135e-02,  1.9848e-03,  5.5552e-03, -3.0141e-03,\n",
       "        -1.2028e-04, -2.6739e-03, -7.8973e-04, -1.2256e-02,  1.1130e-02,\n",
       "        -2.1308e-02, -1.5121e-03, -8.4693e-03, -9.0220e-03, -1.5707e-03,\n",
       "         2.1435e-02, -1.4622e-02, -1.1779e-02,  3.0766e-03, -1.7704e-03,\n",
       "        -1.3916e-02, -7.2216e-03, -1.0567e-03, -9.6687e-04, -4.2216e-03,\n",
       "        -1.2833e-02, -2.7412e-04,  6.6940e-04, -4.7578e-03, -5.6300e-03,\n",
       "        -1.2190e-02, -4.4394e-03,  5.1390e-03,  1.3539e-02,  9.9249e-03,\n",
       "         1.4757e-02,  2.6018e-03, -4.3809e-03,  2.4684e-02, -1.1273e-02,\n",
       "         1.2729e-02, -5.1084e-03, -1.1814e-02, -4.9827e-03,  1.4937e-02,\n",
       "        -1.7126e-02,  1.6598e-02,  1.3946e-02,  3.0377e-02,  6.6425e-03,\n",
       "         6.0981e-03, -3.3217e-03,  8.1140e-03, -1.6228e-03,  1.9549e-02,\n",
       "         2.6386e-02, -8.1902e-04,  2.5420e-03,  7.9035e-03,  9.1169e-03,\n",
       "         1.6212e-02, -4.3473e-03,  1.0761e-02,  1.7077e-03, -1.4481e-02,\n",
       "        -5.2910e-03, -2.2974e-02, -2.0641e-02,  1.0192e-02,  1.0545e-02,\n",
       "        -9.7636e-03,  1.8227e-02, -8.2728e-03,  8.9075e-03, -2.2620e-03,\n",
       "        -9.6952e-03, -5.0159e-03,  7.1226e-03,  2.8585e-02, -8.3582e-05,\n",
       "         2.1185e-03, -7.7900e-03,  1.7819e-02, -8.3359e-03, -2.5210e-02,\n",
       "         5.0447e-03,  1.5186e-03,  4.7860e-03, -1.5937e-02,  2.5210e-02,\n",
       "         1.7711e-02,  1.0091e-03,  3.7658e-04, -1.9004e-04,  2.4856e-03,\n",
       "         3.5618e-02, -1.4573e-02, -1.6398e-02,  3.4927e-03,  2.5905e-03,\n",
       "        -5.4803e-04, -5.2864e-03,  1.7263e-02, -8.6483e-04,  1.9328e-04,\n",
       "         1.3726e-02,  6.9260e-03,  1.4363e-02,  2.0397e-02, -8.4448e-03,\n",
       "        -5.5349e-03, -1.8207e-03,  2.2978e-02,  1.9817e-02, -1.5055e-02,\n",
       "        -6.0768e-03,  1.8341e-02,  1.4490e-02, -1.8010e-03,  1.1170e-02,\n",
       "         1.0210e-02,  1.8254e-02, -8.1524e-03,  1.0713e-02, -5.9407e-03,\n",
       "        -6.2752e-03, -2.9218e-02, -1.6438e-02, -3.8385e-03,  2.4974e-02,\n",
       "         1.7872e-02, -2.0053e-02, -1.8510e-02,  9.9373e-04, -1.9877e-02,\n",
       "        -6.1206e-03, -1.2718e-02, -8.8157e-03, -1.1485e-02,  2.1413e-02,\n",
       "         9.8183e-03, -8.0588e-03, -2.4606e-03, -1.0453e-02,  6.4749e-03,\n",
       "        -1.2692e-02, -1.2120e-03, -8.2088e-03, -1.5537e-02, -1.3258e-02,\n",
       "         4.4749e-03, -4.2462e-03, -1.3773e-02, -1.8466e-02, -7.4500e-03,\n",
       "         3.2231e-03, -2.2158e-03, -7.6571e-03, -2.4689e-03, -1.5317e-03,\n",
       "         2.6943e-03,  7.9552e-04, -3.7696e-03, -1.4036e-02, -2.6654e-04,\n",
       "        -6.5476e-03, -1.2888e-04, -1.9731e-04, -1.4204e-04, -1.9490e-02,\n",
       "        -1.1283e-03,  3.8485e-03, -1.3964e-02, -9.2690e-03, -1.8712e-02,\n",
       "        -9.7369e-04,  2.2355e-02,  2.0221e-02,  7.1197e-03,  9.9006e-03,\n",
       "        -1.1104e-02,  5.4583e-03,  9.0527e-03, -4.2292e-03, -3.0734e-05,\n",
       "         9.2553e-03,  1.4336e-02,  2.5846e-02,  5.2189e-03, -1.1753e-02,\n",
       "         1.8853e-02, -6.9766e-03,  1.0509e-02, -1.1962e-02,  7.0652e-03,\n",
       "         1.0629e-03, -1.6302e-02, -1.9871e-03, -7.4473e-03,  1.7128e-03,\n",
       "         3.0291e-03, -1.2221e-02, -1.4638e-02, -3.3854e-02, -1.1569e-02,\n",
       "        -1.6404e-02, -4.0354e-03, -1.3008e-02,  7.7703e-03,  2.4369e-03])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet(\n",
      "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "  (layer1): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (3): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (4): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (5): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (layer4): Sequential(\n",
      "    (0): Bottleneck(\n",
      "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (downsample): Sequential(\n",
      "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "    (1): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "    (2): Bottleneck(\n",
      "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Dropout(p=0.2, inplace=False)\n",
      "    (3): Linear(in_features=512, out_features=4, bias=True)\n",
      "    (4): LogSoftmax(dim=1)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# 4 for 4 classes\n",
    "\n",
    "model.fc = nn.Sequential(nn.Linear(2048, 512),\n",
    "                         nn.ReLU(),\n",
    "                         nn.Dropout(0.2),\n",
    "                         nn.Linear(512, 4),\n",
    "                         nn.LogSoftmax(dim=1))\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Sequential(\n",
       "    (0): Linear(in_features=2048, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "    (3): Linear(in_features=512, out_features=4, bias=True)\n",
       "    (4): LogSoftmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.003)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1600974578.8110561\n"
     ]
    }
   ],
   "source": [
    "traintime = time.time()\n",
    "print(traintime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150.. Train loss: 2.827.. validation loss: 1.115.. Validation accuracy: 0.594\n",
      "Device = cpu; Time per batch: 1.185 seconds\n",
      "Epoch 2/150.. Train loss: 1.348.. validation loss: 1.117.. Validation accuracy: 0.576\n",
      "Device = cpu; Time per batch: 1.247 seconds\n",
      "Epoch 3/150.. Train loss: 1.198.. validation loss: 1.076.. Validation accuracy: 0.538\n",
      "Device = cpu; Time per batch: 1.198 seconds\n",
      "Epoch 4/150.. Train loss: 1.086.. validation loss: 0.970.. Validation accuracy: 0.677\n",
      "Device = cpu; Time per batch: 1.253 seconds\n",
      "Epoch 5/150.. Train loss: 1.007.. validation loss: 0.972.. Validation accuracy: 0.601\n",
      "Device = cpu; Time per batch: 1.151 seconds\n",
      "Epoch 6/150.. Train loss: 0.916.. validation loss: 0.821.. Validation accuracy: 0.740\n",
      "Device = cpu; Time per batch: 1.095 seconds\n",
      "Epoch 7/150.. Train loss: 0.872.. validation loss: 0.799.. Validation accuracy: 0.691\n",
      "Device = cpu; Time per batch: 1.171 seconds\n",
      "Epoch 8/150.. Train loss: 0.859.. validation loss: 0.648.. Validation accuracy: 0.826\n",
      "Device = cpu; Time per batch: 1.257 seconds\n",
      "Epoch 9/150.. Train loss: 0.867.. validation loss: 0.621.. Validation accuracy: 0.767\n",
      "Device = cpu; Time per batch: 1.208 seconds\n",
      "Epoch 10/150.. Train loss: 0.839.. validation loss: 0.658.. Validation accuracy: 0.791\n",
      "Device = cpu; Time per batch: 1.130 seconds\n",
      "Epoch 11/150.. Train loss: 0.811.. validation loss: 0.742.. Validation accuracy: 0.765\n",
      "Device = cpu; Time per batch: 1.179 seconds\n",
      "Epoch 12/150.. Train loss: 0.872.. validation loss: 0.754.. Validation accuracy: 0.740\n",
      "Device = cpu; Time per batch: 1.128 seconds\n",
      "Epoch 13/150.. Train loss: 0.805.. validation loss: 0.876.. Validation accuracy: 0.659\n",
      "Device = cpu; Time per batch: 1.197 seconds\n",
      "Epoch 14/150.. Train loss: 0.789.. validation loss: 0.591.. Validation accuracy: 0.785\n",
      "Device = cpu; Time per batch: 1.141 seconds\n",
      "Epoch 15/150.. Train loss: 0.785.. validation loss: 0.599.. Validation accuracy: 0.781\n",
      "Device = cpu; Time per batch: 1.176 seconds\n",
      "Epoch 16/150.. Train loss: 0.786.. validation loss: 0.569.. Validation accuracy: 0.798\n",
      "Device = cpu; Time per batch: 1.233 seconds\n",
      "Epoch 17/150.. Train loss: 0.786.. validation loss: 0.765.. Validation accuracy: 0.698\n",
      "Device = cpu; Time per batch: 1.172 seconds\n",
      "Epoch 18/150.. Train loss: 0.774.. validation loss: 0.585.. Validation accuracy: 0.732\n",
      "Device = cpu; Time per batch: 1.152 seconds\n",
      "Epoch 19/150.. Train loss: 0.748.. validation loss: 0.586.. Validation accuracy: 0.775\n",
      "Device = cpu; Time per batch: 1.222 seconds\n",
      "Epoch 20/150.. Train loss: 0.746.. validation loss: 0.540.. Validation accuracy: 0.816\n",
      "Device = cpu; Time per batch: 1.198 seconds\n",
      "Epoch 21/150.. Train loss: 0.775.. validation loss: 0.629.. Validation accuracy: 0.667\n",
      "Device = cpu; Time per batch: 1.108 seconds\n",
      "Epoch 22/150.. Train loss: 0.774.. validation loss: 0.670.. Validation accuracy: 0.669\n",
      "Device = cpu; Time per batch: 1.122 seconds\n",
      "Epoch 23/150.. Train loss: 0.745.. validation loss: 0.711.. Validation accuracy: 0.659\n",
      "Device = cpu; Time per batch: 1.156 seconds\n",
      "Epoch 24/150.. Train loss: 0.737.. validation loss: 0.557.. Validation accuracy: 0.801\n",
      "Device = cpu; Time per batch: 1.144 seconds\n",
      "Epoch 25/150.. Train loss: 0.749.. validation loss: 0.531.. Validation accuracy: 0.783\n",
      "Device = cpu; Time per batch: 1.132 seconds\n",
      "Epoch 26/150.. Train loss: 0.726.. validation loss: 0.614.. Validation accuracy: 0.698\n",
      "Device = cpu; Time per batch: 1.144 seconds\n",
      "Epoch 27/150.. Train loss: 0.715.. validation loss: 0.519.. Validation accuracy: 0.842\n",
      "Device = cpu; Time per batch: 1.158 seconds\n",
      "Epoch 28/150.. Train loss: 0.757.. validation loss: 0.555.. Validation accuracy: 0.759\n",
      "Device = cpu; Time per batch: 1.141 seconds\n",
      "Epoch 29/150.. Train loss: 0.789.. validation loss: 0.711.. Validation accuracy: 0.683\n",
      "Device = cpu; Time per batch: 1.166 seconds\n",
      "Epoch 30/150.. Train loss: 0.768.. validation loss: 0.663.. Validation accuracy: 0.665\n",
      "Device = cpu; Time per batch: 1.130 seconds\n",
      "Epoch 31/150.. Train loss: 0.756.. validation loss: 0.542.. Validation accuracy: 0.814\n",
      "Device = cpu; Time per batch: 1.127 seconds\n",
      "Epoch 32/150.. Train loss: 0.720.. validation loss: 0.641.. Validation accuracy: 0.765\n",
      "Device = cpu; Time per batch: 1.170 seconds\n",
      "Epoch 33/150.. Train loss: 0.742.. validation loss: 0.692.. Validation accuracy: 0.652\n",
      "Device = cpu; Time per batch: 1.186 seconds\n",
      "Epoch 34/150.. Train loss: 0.719.. validation loss: 0.566.. Validation accuracy: 0.775\n",
      "Device = cpu; Time per batch: 1.176 seconds\n",
      "Epoch 35/150.. Train loss: 0.705.. validation loss: 0.566.. Validation accuracy: 0.757\n",
      "Device = cpu; Time per batch: 1.135 seconds\n",
      "Epoch 36/150.. Train loss: 0.721.. validation loss: 0.585.. Validation accuracy: 0.720\n",
      "Device = cpu; Time per batch: 1.169 seconds\n",
      "Epoch 37/150.. Train loss: 0.775.. validation loss: 0.545.. Validation accuracy: 0.761\n",
      "Device = cpu; Time per batch: 1.124 seconds\n",
      "Epoch 38/150.. Train loss: 0.742.. validation loss: 0.502.. Validation accuracy: 0.803\n",
      "Device = cpu; Time per batch: 1.133 seconds\n",
      "Epoch 39/150.. Train loss: 0.776.. validation loss: 0.607.. Validation accuracy: 0.789\n",
      "Device = cpu; Time per batch: 1.121 seconds\n"
     ]
    }
   ],
   "source": [
    "epochs = 300\n",
    "training_loss = 0\n",
    "\n",
    "train_losses, valid_losses = [], []\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for images, labels in trainloader:\n",
    "\n",
    "        # move the variables to GPU\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        logps = model(images)\n",
    "        loss = criterion(logps, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        training_loss += loss.item()\n",
    "\n",
    "    else:\n",
    "        test_loss = 0\n",
    "        accuracy = 0\n",
    "\n",
    "        # turn of dropouts\n",
    "        model.eval()\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            for images, labels in validloader:\n",
    "                # move the variables to GPU\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "                start = time.time()\n",
    "\n",
    "                logps = model(images)\n",
    "                loss = criterion(logps, labels)\n",
    "                test_loss += loss.item()\n",
    "\n",
    "                # Calculate accuracy\n",
    "                ps = torch.exp(logps)\n",
    "                top_prob, top_class = ps.topk(1, dim=1)\n",
    "                targets = labels.view(*top_class.shape)\n",
    "                isEqual = top_class == targets\n",
    "                accuracy += torch.mean(isEqual.type(torch.FloatTensor))\n",
    "\n",
    "            train_losses.append(training_loss / len(trainloader))\n",
    "            valid_losses.append(test_loss / len(validloader))\n",
    "\n",
    "            print(f\"Epoch {epoch+1}/{epochs}.. \"\n",
    "                  f\"Train loss: {training_loss/len(trainloader):.3f}.. \"\n",
    "                  f\"validation loss: {test_loss/len(validloader):.3f}.. \"\n",
    "                  f\"Validation accuracy: {accuracy/len(validloader):.3f}\")\n",
    "            print(f\"Device = {device}; Time per batch: {(time.time() - start)/len(validloader):.3f} seconds\")\n",
    "\n",
    "            training_loss = 0\n",
    "\n",
    "            # switch back to training\n",
    "            model.train()\n",
    "\n",
    "print(f\" \\nTotal Time : {(time.time() - traintime)/60:.3f} minutes\")\n",
    "\n",
    "print(\"Training losses: \", train_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'model_300_epoch_sep24.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=torch.load('model_300_epoch_sep24.pth')\n",
    "#model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_losses, label='Training loss')\n",
    "plt.plot(valid_losses, label='Validation loss')\n",
    "plt.legend(frameon=False)\n",
    "plt.savefig('train_validation_loss.png')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=64)\n",
    "\n",
    "test_classes = [label for _, label in test_dataset]\n",
    "print(\"Test Data: \", Counter(test_classes))\n",
    "print(len(testloader.dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model=torch.load('model_300_epoch_sep24.pth')\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_output_classes = len(trainloader.dataset.classes)\n",
    "num_output_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader.dataset.classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the checkpoint\n",
    "Now that your network is trained, save the model so you can load it later for making predictions. You probably want to save other things such as the mapping of classes to indices which you get from one of the image datasets: image_datasets['train'].class_to_idx. You can attach this to the model as an attribute which makes inference easier later on.\n",
    "\n",
    "model.class_to_idx = image_datasets['train'].class_to_idx\n",
    "\n",
    "Remember that you'll want to completely rebuild the model later so you can use it for inference. Make sure to include any information you need in the checkpoint. If you want to load the model and keep training, you'll want to save the number of epochs as well as the optimizer state, optimizer.state_dict. You'll likely want to use this trained model in the next part of the project, so best to save it now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Save the checkpoint \n",
    "checkpoint = {'pretrained_model_name' : \"resnet50\",\n",
    "              'input_size' : 2048,\n",
    "              'output_size' : 4,\n",
    "              'hidden_layer' : 512,\n",
    "              'model_state_dict': model.state_dict(),\n",
    "              'optim_state_dict' : optimizer.state_dict(),\n",
    "              'class_to_idx': trainloader.dataset.classes,\n",
    "              'train_losses': train_losses,\n",
    "              'valid_losses' : valid_losses}\n",
    "\n",
    "torch.save(checkpoint, 'model_300_epoch_sep24_checkpoint')\n",
    "\n",
    "model.to(\"cpu\")\n",
    "checkpoint = {'pretrained_model_name' : \"resnet50\",\n",
    "              'input_size' : 2048,\n",
    "              'output_size' : 4,\n",
    "              'hidden_layer' : 512,\n",
    "              'model_state_dict': model.state_dict(),\n",
    "              'optim_state_dict' : optimizer.state_dict(),\n",
    "              'class_to_idx': trainloader.dataset.classes,\n",
    "              'train_losses': train_losses,\n",
    "              'valid_losses' : valid_losses}\n",
    "\n",
    "torch.save(checkpoint, 'model_300_epoch_sep24_checkpoint')\n",
    "#model.to(\"cuda\")\n",
    "\n",
    "#train_data.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Write a function that loads a checkpoint and rebuilds the model\n",
    "def load_Checkpoint(filename):\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        checkpoint = torch.load(filename)\n",
    "    else:\n",
    "        checkpoint = torch.load(filename,map_location='cpu')\n",
    "        \n",
    "    # get pre-trained model\n",
    "    model1 = models.resnet50(pretrained=True)\n",
    "    \n",
    "    # freeze parameters - to prevent gradients and backprop\n",
    "    for param in model1.parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    # TODO - this function should load for any architecture\n",
    "    \n",
    "    classifier = nn.Sequential(nn.Linear(2048, 512),\n",
    "                               nn.ReLU(),\n",
    "                               nn.Dropout(p=0.2),\n",
    "                               nn.Linear(512, 4),\n",
    "                               nn.LogSoftmax(dim=1)\n",
    "                              )\n",
    "    \n",
    "                  \n",
    "    model1.fc = classifier   \n",
    "    \n",
    "    \n",
    "    model1.load_state_dict(checkpoint['model_state_dict'])\n",
    "    \n",
    "    model1.class_to_idx = checkpoint['class_to_idx']\n",
    "    \n",
    "    return model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test saving and loading\n",
    "criterion = nn.NLLLoss()\n",
    "new_model = load_Checkpoint('model_300_epoch_sep24_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_image(image):\n",
    "    ''' Scales, crops, and normalizes a PIL image for a PyTorch model,\n",
    "        returns an Numpy array\n",
    "    '''\n",
    "    # TODO: Process a PIL image for use in a PyTorch model\n",
    "    \n",
    "    crop_size = 224\n",
    "    new_width = 256\n",
    "    # ImageNet mean and std    \n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "\n",
    "    # 1. Resize with shortest side 256 and maintain aspect ratio\n",
    "    width, height = image.size\n",
    "    orig_ar = width / height\n",
    "    if width < height:\n",
    "        new_width = 256\n",
    "        new_height = new_width / orig_ar\n",
    "    elif width > height:\n",
    "        new_height = 256\n",
    "        new_width = new_height * orig_ar\n",
    "    else:\n",
    "        new_width = new_height = 256\n",
    "    image.thumbnail((new_width, new_height), Image.ANTIALIAS)\n",
    "\n",
    "    # 2. center crop\n",
    "    left = int((new_width - crop_size) / 2)\n",
    "    top = int((new_height - crop_size) / 2)\n",
    "    right = int((new_width + crop_size) / 2)\n",
    "    bottom = int((new_height + crop_size) / 2)\n",
    "    image = image.crop((left, top, right, bottom))\n",
    "    \n",
    "    # 3. PIL to nparray - 0-255\n",
    "    np_image = np.array(image)\n",
    "    # scale : 0 to 1 range\n",
    "    np_image = np_image / 255.0\n",
    "    \n",
    "    # 4. Normalize the image\n",
    "    np_image = (np_image - mean) / std\n",
    "\n",
    "    # 5. re-order color channels\n",
    "    out_image = np.transpose(np_image, (2, 0, 1))\n",
    "    \n",
    "    return out_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(image, ax=None, title=None):\n",
    "    \"\"\"Imshow for Tensor.\"\"\"\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # PyTorch tensors assume the color channel is the first dimension\n",
    "    # but matplotlib assumes is the third dimension\n",
    "    image = image.numpy().transpose((1, 2, 0))\n",
    "    \n",
    "    # Undo preprocessing\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    image = std * image + mean\n",
    "    \n",
    "    # Image needs to be clipped between 0 and 1 or it looks like noise when displayed\n",
    "    image = np.clip(image, 0, 1)\n",
    "    \n",
    "    ax.imshow(image)\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test  - process_image()\n",
    "from PIL import Image\n",
    "\n",
    "image_path = '/Users/sm912r/PycharmProjects/CV/pinnacle_buried_wire_usecase_train_test/test/test_data/img_1.jpeg'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "image_ndarray = process_image(image)\n",
    "image_torch = torch.from_numpy(image_ndarray)\n",
    "imshow(image_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(image_path, new_model, device, topk=10):\n",
    "    ''' Predict the class (or classes) of an image using a trained deep learning model.\n",
    "    '''\n",
    "    \n",
    "    # TODO: Implement the code to predict the class from an image file\n",
    "    image = Image.open(image_path)\n",
    "\n",
    "    image_ndarray = process_image(image)\n",
    "    \n",
    "    # turn off dropouts\n",
    "    new_model.eval()\n",
    "    \n",
    "    new_model.to(device)\n",
    "\n",
    "    # create a torch tensor of type float32\n",
    "    image_torch = torch.from_numpy(image_ndarray).type(torch.FloatTensor)\n",
    "\n",
    "    # reshape to incorporate batch size\n",
    "    batch_t = torch.unsqueeze(image_torch, 0)\n",
    "    \n",
    "    logps = new_model(batch_t)\n",
    "    ps = torch.exp(logps)\n",
    "    top_prob, top_idx = ps.topk(topk,dim=1)\n",
    "        \n",
    "    # index to class mapping\n",
    "    # idx_to_class = {value : key for key, value in new_model.class_to_idx.items()}\n",
    "    \n",
    "    # convert torch to numpy\n",
    "    top_idx = top_idx.tolist()[0]\n",
    "    # top_class = [ idx_to_class[entry] for entry in top_idx]\n",
    "    top_class = []\n",
    "    #print(\"top_idx: \", top_idx)\n",
    "    # print(\"TOP INDEX: \", top_idx[0])\n",
    "    return top_prob.tolist()[0], top_class, top_idx[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_classify(img, top_class, topk, cat_to_name):\n",
    "\n",
    "    class_names = [ cat_to_name[item] for item in top_class]\n",
    "    print(class_names)\n",
    "    \n",
    "    fig, (ax1, ax2) = plt.subplots(figsize=(6,9), ncols=2)    \n",
    "    ax1 = imshow(image_torch, ax = ax1)\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    \n",
    "    y_pos = np.arange(topk)\n",
    "    ax2.barh(np.arange(topk), list(reversed(top_prob)))\n",
    "    ax2.set_aspect(0.1)\n",
    "    ax2.set_yticks(np.arange(topk))\n",
    "    ax2.set_yticklabels(reversed(class_names), size='small');\n",
    "    ax2.set_title('Class Probability')\n",
    "    ax2.set_xlim(0, 1.1)\n",
    "\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model.class_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test prediction\n",
    "with torch.no_grad():   \n",
    "    \n",
    "    image_path = '/Users/sm912r/PycharmProjects/CV/pinnacle_buried_wire_usecase_train_test/test/test_data/img_1.jpeg' # pink primrose\n",
    "    #image_path = '/Users/sm912r/Downloads/pinnacle_buried_wire_usecase_train_test/train/0-0-0-1/img_613.jpeg' #hard-leaved pocket orchid\n",
    "    #image_path = '/Users/sm912r/PycharmProjects/CV/pinnacle_buried_wire_usecase_train_test/train/0-1-0-0/img_382.jpg' #morning glory\n",
    "    #image_path = r'flowers/test/17/' + 'image_03830.jpg' # purple coneflower\n",
    "    #image_path = r'flowers/test/74/' + 'image_01307.jpg' # rose\n",
    "    #image_path = r'flowers/test/78/' + 'image_01903.jpg' # lotus lotus\n",
    "    #image_path = r'flowers/test/18/' + 'image_04272.jpg' # peruvian lily * 4th\n",
    "    #image_path = r'flowers/test/15/' + 'image_06351.jpg' # yellow iris * 5th\n",
    "        \n",
    "    topk = 4\n",
    "\n",
    "    top_prob, top_class, top_idx = predict(image_path, new_model, device=\"cpu\", topk=4)\n",
    "\n",
    "    image = Image.open(image_path)\n",
    "    image_ndarray = process_image(image)\n",
    "    image_torch = torch.from_numpy(image_ndarray)\n",
    "    #imshow(image_torch)\n",
    "\n",
    "    print(top_prob)\n",
    "    print(top_class)\n",
    "    \n",
    "    # view_classify(image_torch, top_class, topk, cat_to_name)\n",
    "    \n",
    "    print(\"\\n\\n ** prediction - results **\")\n",
    "\n",
    "    #class_names = [cat_to_name[item] for item in top_class]\n",
    "\n",
    "    #print(\"Class name : \", class_names[0])\n",
    "    #print(\"Class number : \", top_class[0])\n",
    "    print(\"Probability : \", top_prob[0], \"\\n\")\n",
    "    print(\"{'0-0-0-1': 0, '0-0-1-0': 1, '0-1-0-0': 2, '1-0-0-0': 3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "test_names = os.listdir('/Users/sm912r/PycharmProjects/CV/pinnacle_buried_wire_usecase_train_test/test/test_data/')\n",
    "#print(test_names)\n",
    "print(len(test_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'/Users/sm912r/PycharmProjects/CV/pinnacle_buried_wire_usecase_train_test/test/test_data/' + test_names[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test prediction\n",
    "with torch.no_grad():   \n",
    "    topk = 4\n",
    "    for i in range(len(test_names)):\n",
    "        image_path = '/Users/sm912r/PycharmProjects/CV/pinnacle_buried_wire_usecase_train_test/test/test_data/' + test_names[i]\n",
    "        print(\"Test data: \", test_names[i])\n",
    "        top_prob, top_class = predict(image_path, new_model, device=\"cpu\", topk=4)\n",
    "        image = Image.open(image_path)\n",
    "        image_ndarray = process_image(image)\n",
    "        image_torch = torch.from_numpy(image_ndarray)\n",
    "        #print(top_prob)\n",
    "        #print(\"\\n\\n ** prediction - results **\")\n",
    "        print(\"Probability : \", top_prob[0], \"\\n\")\n",
    "        \n",
    "    print(\"{'0-0-0-1': 0, '0-0-1-0': 1, '0-1-0-0': 2, '1-0-0-0': 3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test prediction\n",
    "with torch.no_grad():   \n",
    "    topk = 4\n",
    "    for i in range(len(test_names)):\n",
    "        image_path = '/Users/sm912r/PycharmProjects/CV/pinnacle_buried_wire_usecase_train_test/test/test_data/' + test_names[i]\n",
    "        # print(\"Test data: \", test_names[i])\n",
    "        top_prob, top_class, top_idx = predict(image_path, new_model, device=\"cpu\", topk=4)\n",
    "        image = Image.open(image_path)\n",
    "        image_ndarray = process_image(image)\n",
    "        image_torch = torch.from_numpy(image_ndarray)\n",
    "        #print(top_prob)\n",
    "        #print(\"\\n\\n ** prediction - results **\")\n",
    "        #print(\"Probability : \", top_prob[0], \"\\n\")\n",
    "        print(test_names[i],\",\", top_idx)\n",
    "        \n",
    "    print(\"{'0-0-0-1': 0, '0-0-1-0': 1, '0-1-0-0': 2, '1-0-0-0': 3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
